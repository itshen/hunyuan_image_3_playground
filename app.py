#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
HunyuanImage API æµ‹è¯•å·¥å…· - Web æœåŠ¡

Copyright (c) 2025 Miyang Tech (Zhuhai Hengqin) Co., Ltd.
MIT License
"""

import sys
import json
import uuid
import asyncio
import aiosqlite
import time
import traceback
from datetime import datetime, timezone, timedelta
from pathlib import Path
from typing import Dict, Any, List

from contextlib import asynccontextmanager
from fastapi import FastAPI, Request, UploadFile, File
from fastapi.responses import HTMLResponse, JSONResponse, FileResponse, StreamingResponse
from fastapi.staticfiles import StaticFiles
import uvicorn

sys.path.insert(0, str(Path(__file__).parent.parent))
# api_client.py åœ¨åŒç›®å½•ä¸‹
import sys
sys.path.insert(0, str(Path(__file__).parent))
from api_client import HunyuanImageClient

# ============ è·¯å¾„ & å¸¸é‡ ============

SCRIPT_DIR = Path(__file__).parent
STATIC_DIR = SCRIPT_DIR / "static"
OUTPUT_DIR = SCRIPT_DIR / "output"
UPLOADS_DIR = SCRIPT_DIR / "uploads"
DB_PATH = SCRIPT_DIR / "data.db"

for d in (OUTPUT_DIR, STATIC_DIR, UPLOADS_DIR):
    d.mkdir(parents=True, exist_ok=True)

PORT = 8849
BJT = timezone(timedelta(hours=8))  # åŒ—äº¬æ—¶é—´

# ä»»åŠ¡é˜Ÿåˆ—ç³»ç»Ÿ
active_jobs: Dict[str, Dict[str, Any]] = {}
task_queue: asyncio.PriorityQueue = None  # åœ¨ lifespan ä¸­åˆå§‹åŒ–ï¼Œä½¿ç”¨ä¼˜å…ˆçº§é˜Ÿåˆ—
queue_worker_task = None
queue_counter = 0  # ç”¨äºä¿è¯ç›¸åŒä¼˜å…ˆçº§æ—¶æŒ‰å…¥é˜Ÿé¡ºåºæ‰§è¡Œ


def now_bjt() -> str:
    """è¿”å›åŒ—äº¬æ—¶é—´ ISO å­—ç¬¦ä¸²"""
    return datetime.now(BJT).strftime("%Y-%m-%d %H:%M:%S")


# ============ æ•°æ®åº“ ============

async def init_db():
    async with aiosqlite.connect(DB_PATH) as db:
        await db.execute("""
            CREATE TABLE IF NOT EXISTS images (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                job_id TEXT NOT NULL,
                filename TEXT NOT NULL,
                prompt TEXT,
                seed INTEGER DEFAULT 42,
                image_size TEXT DEFAULT 'auto',
                width INTEGER DEFAULT 1024,
                height INTEGER DEFAULT 1024,
                steps INTEGER DEFAULT 50,
                api_url TEXT,
                status TEXT DEFAULT 'completed',
                error TEXT,
                info TEXT,
                duration_sec REAL DEFAULT 0,
                batch_count INTEGER DEFAULT 1,
                batch_total_sec REAL DEFAULT 0,
                parallel INTEGER DEFAULT 1,
                ref_images TEXT,
                created_at TEXT,
                sort_order INTEGER DEFAULT 0
            )
        """)
        await db.commit()
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦æ·»åŠ å­—æ®µï¼ˆæ—§æ•°æ®åº“å‡çº§ï¼‰
        cursor = await db.execute("PRAGMA table_info(images)")
        columns = [row[1] for row in await cursor.fetchall()]
        if "ref_images" not in columns:
            await db.execute("ALTER TABLE images ADD COLUMN ref_images TEXT")
            await db.commit()
            print("âœ… æ•°æ®åº“å·²å‡çº§ï¼šæ·»åŠ  ref_images å­—æ®µ")
        if "sort_order" not in columns:
            await db.execute("ALTER TABLE images ADD COLUMN sort_order INTEGER DEFAULT 0")
            await db.commit()
            # åˆå§‹åŒ– sort_orderï¼šæŒ‰ created_at å€’åºèµ‹å€¼
            await db.execute("""
                UPDATE images SET sort_order = (
                    SELECT COUNT(*) FROM images AS i2 
                    WHERE i2.created_at > images.created_at OR 
                          (i2.created_at = images.created_at AND i2.id > images.id)
                )
            """)
            await db.commit()
            print("âœ… æ•°æ®åº“å·²å‡çº§ï¼šæ·»åŠ  sort_order å­—æ®µ")
    print("âœ… æ•°æ®åº“å·²åˆå§‹åŒ–")


@asynccontextmanager
async def lifespan(app: FastAPI):
    global task_queue, queue_worker_task
    # å¯åŠ¨æ—¶åˆå§‹åŒ–
    await init_db()
    task_queue = asyncio.PriorityQueue()  # ä½¿ç”¨ä¼˜å…ˆçº§é˜Ÿåˆ—
    queue_worker_task = asyncio.create_task(queue_worker())
    print("âœ… ä»»åŠ¡é˜Ÿåˆ—å·²å¯åŠ¨")
    yield
    # å…³é—­æ—¶æ¸…ç†
    if queue_worker_task:
        queue_worker_task.cancel()
        try:
            await queue_worker_task
        except asyncio.CancelledError:
            pass


app = FastAPI(title="HunyuanImage API æµ‹è¯•å·¥å…·", lifespan=lifespan)

app.mount("/output", StaticFiles(directory=str(OUTPUT_DIR)), name="output")
app.mount("/uploads", StaticFiles(directory=str(UPLOADS_DIR)), name="uploads")
app.mount("/static", StaticFiles(directory=str(STATIC_DIR)), name="static")


async def get_next_sort_order():
    """è·å–ä¸‹ä¸€ä¸ª sort_order å€¼ï¼ˆæœ€å°å€¼ - 1ï¼Œç¡®ä¿æ–°å›¾ç‰‡æ’åœ¨æœ€å‰é¢ï¼‰"""
    async with aiosqlite.connect(DB_PATH) as db:
        cursor = await db.execute("SELECT MIN(sort_order) FROM images")
        row = await cursor.fetchone()
        min_order = row[0] if row[0] is not None else 0
        return min_order - 1


async def save_image_record(*, job_id, filename, prompt, seed, image_size, width, height,
                            steps, api_url, status="completed", error=None, info=None,
                            duration_sec=0, batch_count=1, batch_total_sec=0, parallel=True,
                            ref_images=None):
    # ref_images æ˜¯æ–‡ä»¶ååˆ—è¡¨ï¼Œå­˜å‚¨ä¸º JSON å­—ç¬¦ä¸²
    ref_images_str = json.dumps(ref_images) if ref_images else None
    sort_order = await get_next_sort_order()
    async with aiosqlite.connect(DB_PATH) as db:
        await db.execute("""
            INSERT INTO images (job_id, filename, prompt, seed, image_size, width, height, steps, api_url, status, error, info, duration_sec, batch_count, batch_total_sec, parallel, ref_images, created_at, sort_order)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        """, (job_id, filename, prompt, seed, image_size, width, height, steps, api_url, status, error, info, duration_sec, batch_count, batch_total_sec, 1 if parallel else 0, ref_images_str, now_bjt(), sort_order))
        await db.commit()


async def update_batch_total(job_id: str, batch_total_sec: float):
    """æ‰¹æ¬¡ç»“æŸåå›å¡«æ€»è€—æ—¶"""
    async with aiosqlite.connect(DB_PATH) as db:
        await db.execute(
            "UPDATE images SET batch_total_sec = ? WHERE job_id = ?",
            (batch_total_sec, job_id)
        )
        await db.commit()


async def get_history(limit: int = 100):
    async with aiosqlite.connect(DB_PATH) as db:
        db.row_factory = aiosqlite.Row
        cursor = await db.execute("SELECT * FROM images ORDER BY sort_order ASC LIMIT ?", (limit,))
        rows = await cursor.fetchall()
        return [dict(row) for row in rows]


async def delete_image_record(image_id: int):
    async with aiosqlite.connect(DB_PATH) as db:
        cursor = await db.execute("SELECT filename FROM images WHERE id = ?", (image_id,))
        row = await cursor.fetchone()
        if row and row[0]:
            fp = OUTPUT_DIR / row[0]
            if fp.exists():
                fp.unlink()
        await db.execute("DELETE FROM images WHERE id = ?", (image_id,))
        await db.commit()


async def clear_all_records():
    async with aiosqlite.connect(DB_PATH) as db:
        await db.execute("DELETE FROM images")
        await db.commit()
    for f in OUTPUT_DIR.iterdir():
        if f.is_file() and f.suffix in ('.png', '.jpg', '.webp'):
            f.unlink()


# ============ é˜Ÿåˆ— Worker ============

async def queue_worker():
    """åå°ä»»åŠ¡å¤„ç† workerï¼ŒæŒ‰ä¼˜å…ˆçº§æ‰§è¡Œé˜Ÿåˆ—ä¸­çš„ä»»åŠ¡"""
    while True:
        try:
            # ä»ä¼˜å…ˆçº§é˜Ÿåˆ—è·å–ä»»åŠ¡ï¼Œæ ¼å¼ä¸º (priority, counter, job)
            priority, counter, job = await task_queue.get()
            job_id = job["job_id"]
            
            # æ£€æŸ¥ä»»åŠ¡æ˜¯å¦å·²è¢«å–æ¶ˆï¼ˆä»é˜Ÿåˆ—å–å‡ºæ—¶å¯èƒ½å·²è¢«æ ‡è®°å–æ¶ˆï¼‰
            if job_id not in active_jobs:
                print(f"[{now_bjt()}] â­ï¸ è·³è¿‡å·²å–æ¶ˆçš„ä»»åŠ¡: {job_id}")
                task_queue.task_done()
                continue
            
            # æ£€æŸ¥çŠ¶æ€æ˜¯å¦ä¸º cancelled
            if active_jobs[job_id].get("status") == "cancelled":
                print(f"[{now_bjt()}] â­ï¸ è·³è¿‡å·²å–æ¶ˆçš„ä»»åŠ¡: {job_id}")
                active_jobs.pop(job_id, None)
                task_queue.task_done()
                continue
            
            # æ ‡è®°å¼€å§‹æ‰§è¡Œ
            active_jobs[job_id]["status"] = "generating"
            active_jobs[job_id]["started_ts"] = time.time()
            
            print(f"[{now_bjt()}] ğŸš€ å¼€å§‹æ‰§è¡Œä»»åŠ¡: {job_id} (ä¼˜å…ˆçº§: {priority})")
            
            try:
                await execute_generation(job)
            except Exception as e:
                print(f"[{now_bjt()}] âŒ ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {job_id}, {e}")
                traceback.print_exc()
                if job_id in active_jobs:
                    active_jobs[job_id]["status"] = "error"
                    active_jobs[job_id]["error"] = str(e)
            finally:
                task_queue.task_done()
                
        except asyncio.CancelledError:
            break
        except Exception as e:
            print(f"[{now_bjt()}] âŒ Worker å¼‚å¸¸: {e}")
            traceback.print_exc()


async def execute_generation(job: dict):
    """æ‰§è¡Œå•ä¸ªç”Ÿæˆä»»åŠ¡"""
    job_id = job["job_id"]
    prompt = job["prompt"]
    api_url = job["api_url"]
    seed = job["seed"]
    image_size = job["image_size"]
    width = job["width"]
    height = job["height"]
    steps = job["steps"]
    count = job["count"]
    ref_images = job["ref_images"]
    parallel = job["parallel"]
    
    loop = asyncio.get_event_loop()
    batch_start = time.time()
    
    def do_generate_one(idx: int):
        """åŒæ­¥ç”Ÿæˆå•å¼ """
        t0 = time.time()
        client = HunyuanImageClient(api_url)
        
        gradio_images = None
        if ref_images:
            gradio_images = []
            for fname in ref_images:
                if not fname:
                    continue
                lp = UPLOADS_DIR / fname
                if lp.exists():
                    gradio_images.append(client.upload_file(str(lp)))
        
        cur_seed = seed + idx if seed >= 0 else seed
        
        image, info = client.generate(
            prompt=prompt, images=gradio_images, seed=cur_seed,
            image_size=image_size, width=width, height=height,
            diff_infer_steps=steps,
        )
        duration = round(time.time() - t0, 1)
        return idx, image, info, duration, cur_seed
    
    async def run_one(idx: int):
        """æ‰§è¡Œå•å¼ ç”Ÿæˆï¼Œæ”¯æŒå–æ¶ˆæ£€æŸ¥"""
        future = loop.run_in_executor(None, do_generate_one, idx)
        
        # å‘¨æœŸæ€§æ£€æŸ¥æ˜¯å¦è¢«å–æ¶ˆ
        while True:
            # æ¯ 2 ç§’æ£€æŸ¥ä¸€æ¬¡å–æ¶ˆçŠ¶æ€
            done, pending = await asyncio.wait({future}, timeout=2.0)
            
            if done:
                # ä»»åŠ¡å®Œæˆ
                return future.result()
            
            # æ£€æŸ¥æ˜¯å¦è¢«å–æ¶ˆ
            if job_id not in active_jobs or active_jobs.get(job_id, {}).get("status") == "cancelled":
                # ä»»åŠ¡å·²å–æ¶ˆï¼Œå°è¯•å–æ¶ˆ futureï¼ˆè™½ç„¶å¯èƒ½ä¸ä¼šç«‹å³åœæ­¢çº¿ç¨‹ä¸­çš„æ“ä½œï¼‰
                future.cancel()
                raise asyncio.CancelledError(f"ä»»åŠ¡ {job_id} å·²å–æ¶ˆ")
    
    async def save_result(idx, image, info, duration, cur_seed):
        """ä¿å­˜ç»“æœ"""
        if image:
            ts = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"{ts}_{job_id}_{idx}.png"
            image.save(OUTPUT_DIR / filename, format="PNG")
            
            info_str = str(info) if info else ""
            
            # ä»å®é™…å›¾ç‰‡è·å–å°ºå¯¸
            actual_width, actual_height = image.size
            
            await save_image_record(
                job_id=job_id, filename=filename, prompt=prompt, seed=cur_seed,
                image_size=image_size, width=actual_width, height=actual_height,
                steps=steps, api_url=api_url, status="completed",
                info=info_str, duration_sec=duration,
                batch_count=count, batch_total_sec=0, parallel=parallel,
                ref_images=ref_images
            )
            
            # æ›´æ–°ä»»åŠ¡è¿›åº¦
            if job_id in active_jobs:
                active_jobs[job_id]["completed"] = active_jobs[job_id].get("completed", 0) + 1
                active_jobs[job_id]["results"].append({
                    "filename": filename,
                    "url": f"/output/{filename}",
                    "duration": duration,
                    "seed": cur_seed,
                    "info": info_str,
                })
            
            print(f"[{now_bjt()}] âœ… å®Œæˆç¬¬ {idx+1}/{count} å¼ : {filename}")
            return True
        else:
            print(f"[{now_bjt()}] âŒ ç¬¬ {idx+1} å¼ æœªè¿”å›å›¾åƒ")
            return False
    
    def is_cancelled():
        """æ£€æŸ¥ä»»åŠ¡æ˜¯å¦å·²è¢«å–æ¶ˆ"""
        return job_id not in active_jobs or active_jobs.get(job_id, {}).get("status") == "cancelled"
    
    # æ‰§è¡Œç”Ÿæˆ
    if parallel and count > 1:
        # å¹¶å‘æ¨¡å¼
        tasks = [asyncio.ensure_future(run_one(i)) for i in range(count)]
        for coro in asyncio.as_completed(tasks):
            # æ£€æŸ¥æ˜¯å¦å·²å–æ¶ˆ
            if is_cancelled():
                print(f"[{now_bjt()}] â¹ï¸ ä»»åŠ¡å·²å–æ¶ˆï¼Œåœæ­¢å¤„ç†: {job_id}")
                # å–æ¶ˆå‰©ä½™çš„ task
                for t in tasks:
                    if not t.done():
                        t.cancel()
                return
            try:
                idx, image, info, duration, cur_seed = await coro
                await save_result(idx, image, info, duration, cur_seed)
            except asyncio.CancelledError:
                pass  # task è¢«å–æ¶ˆï¼Œè·³è¿‡
            except Exception as e:
                print(f"[{now_bjt()}] âŒ ç”Ÿæˆå¤±è´¥: {e}")
                traceback.print_exc()
    else:
        # é¡ºåºæ¨¡å¼
        for i in range(count):
            # æ£€æŸ¥æ˜¯å¦å·²å–æ¶ˆ
            if is_cancelled():
                print(f"[{now_bjt()}] â¹ï¸ ä»»åŠ¡å·²å–æ¶ˆï¼Œåœæ­¢å¤„ç†: {job_id}")
                return
            try:
                idx, image, info, duration, cur_seed = await run_one(i)
                await save_result(idx, image, info, duration, cur_seed)
            except asyncio.CancelledError:
                print(f"[{now_bjt()}] â¹ï¸ ä»»åŠ¡å·²å–æ¶ˆï¼Œåœæ­¢å¤„ç†: {job_id}")
                return
            except Exception as e:
                print(f"[{now_bjt()}] âŒ ç¬¬ {i+1} å¼ ç”Ÿæˆå¤±è´¥: {e}")
                traceback.print_exc()
    
    # æ‰¹æ¬¡ç»“æŸ
    batch_total = round(time.time() - batch_start, 1)
    
    # å¦‚æœä»»åŠ¡å·²è¢«å–æ¶ˆï¼Œæ¸…ç†å¹¶é€€å‡º
    if job_id not in active_jobs or active_jobs.get(job_id, {}).get("status") == "cancelled":
        active_jobs.pop(job_id, None)
        print(f"[{now_bjt()}] ğŸ—‘ï¸ å·²æ¸…ç†å–æ¶ˆçš„ä»»åŠ¡: {job_id}")
        return
    
    await update_batch_total(job_id, batch_total)
    
    active_jobs[job_id]["status"] = "completed"
    active_jobs[job_id]["batch_total"] = batch_total
    
    print(f"[{now_bjt()}] ğŸ‰ ä»»åŠ¡å®Œæˆ: {job_id}, è€—æ—¶ {batch_total}s")


# ============ å¯åŠ¨ ============



# ============ é¡µé¢ ============

@app.get("/", response_class=HTMLResponse)
async def index():
    p = STATIC_DIR / "index.html"
    return FileResponse(p) if p.exists() else HTMLResponse("<h1>ç¼ºå°‘ static/index.html</h1>")


# ============ API ============

@app.get("/api/history")
async def api_history():
    history = await get_history()
    return JSONResponse({"success": True, "data": history})


@app.get("/api/jobs")
async def api_jobs():
    """è·å–å½“å‰è¿›è¡Œä¸­çš„ä»»åŠ¡åˆ—è¡¨ï¼ˆä¸å«å·²å®Œæˆçš„ï¼‰"""
    jobs = [
        {
            "job_id": jid,
            "prompt": info.get("prompt", ""),
            "count": info.get("count", 1),
            "completed": info.get("completed", 0),
            "status": info.get("status", "pending"),
            "queued_ts": info.get("queued_ts"),
            "started_ts": info.get("started_ts"),  # None è¡¨ç¤ºè¿˜åœ¨æ’é˜Ÿ
            "parallel": info.get("parallel", True),
            "results": info.get("results", []),
            "batch_total": info.get("batch_total"),
            "error": info.get("error"),
            "ratio": info.get("ratio", "auto"),
            "actual_width": info.get("actual_width"),
            "actual_height": info.get("actual_height"),
            "ref_images": info.get("ref_images", []),
        }
        for jid, info in active_jobs.items()
        if info.get("status") not in ("completed", "error")  # åªè¿”å›è¿›è¡Œä¸­çš„
    ]
    return JSONResponse({"success": True, "data": jobs, "queue_size": task_queue.qsize()})


@app.post("/api/upload")
async def api_upload(file: UploadFile = File(...)):
    ext = Path(file.filename).suffix or '.png'
    local_name = f"{uuid.uuid4().hex[:8]}{ext}"
    local_path = UPLOADS_DIR / local_name
    content = await file.read()
    with open(local_path, 'wb') as f:
        f.write(content)
    print(f"ğŸ“¤ å›¾ç‰‡å·²ä¿å­˜: {local_name} ({len(content)} bytes)")
    return JSONResponse({"success": True, "filename": local_name, "url": f"/uploads/{local_name}", "size": len(content)})


@app.post("/api/generate")
async def api_generate(request: Request):
    """æäº¤ç”Ÿæˆä»»åŠ¡åˆ°é˜Ÿåˆ—"""
    global queue_counter
    data = await request.json()

    api_url = data.get("api_url", "").strip()
    prompt = data.get("prompt", "").strip()
    seed = int(data.get("seed", 42))
    image_size = data.get("image_size", "auto")
    width = int(data.get("width", 1024))
    height = int(data.get("height", 1024))
    ratio = data.get("ratio", "auto")  # æ¯”ä¾‹ï¼Œç”¨äºå‰ç«¯æ˜¾ç¤º
    actual_width = int(data.get("actual_width", 1024))  # å®é™…å®½åº¦ï¼ˆæœªäº¤æ¢ï¼‰
    actual_height = int(data.get("actual_height", 1024))  # å®é™…é«˜åº¦ï¼ˆæœªäº¤æ¢ï¼‰
    steps = int(data.get("steps", 50))
    count = int(data.get("count", 1))
    ref_images: List[str] = data.get("ref_images", [])
    parallel = data.get("parallel", True)

    if not api_url:
        return JSONResponse({"success": False, "error": "è¯·è¾“å…¥ API åœ°å€"}, status_code=400)
    if not prompt:
        return JSONResponse({"success": False, "error": "è¯·è¾“å…¥æç¤ºè¯"}, status_code=400)

    count = min(max(count, 1), 4)
    job_id = str(uuid.uuid4())[:8]
    queued_ts = time.time()
    
    # è®¡ç®—é˜Ÿåˆ—ä½ç½®
    queue_position = task_queue.qsize() + 1
    
    # è·å–å½“å‰è®¡æ•°å™¨å€¼å¹¶é€’å¢
    current_counter = queue_counter
    queue_counter += 1

    # æ³¨å†Œä»»åŠ¡ï¼ˆpending çŠ¶æ€ï¼Œstarted_ts ä¸º Noneï¼‰
    active_jobs[job_id] = {
        "prompt": prompt,
        "count": count,
        "parallel": parallel,
        "status": "pending",
        "queued": now_bjt(),
        "queued_ts": queued_ts,
        "started_ts": None,  # å¼€å§‹æ‰§è¡Œæ—¶æ›´æ–°
        "completed": 0,
        "results": [],
        "queue_position": queue_position,
        "priority": 1,  # é»˜è®¤ä¼˜å…ˆçº§ä¸º 1ï¼ˆæ™®é€šä»»åŠ¡ï¼‰
        "counter": current_counter,  # è®°å½•å…¥é˜Ÿé¡ºåº
        "api_url": api_url,
        "seed": seed,
        "image_size": image_size,
        "width": width,
        "height": height,
        "ratio": ratio,  # æ¯”ä¾‹
        "actual_width": actual_width,  # å®é™…å®½åº¦
        "actual_height": actual_height,  # å®é™…é«˜åº¦
        "steps": steps,
        "ref_images": ref_images,
    }

    # åŠ å…¥ä¼˜å…ˆçº§é˜Ÿåˆ—ï¼š(priority, counter, job_data)
    # priority è¶Šå°ä¼˜å…ˆçº§è¶Šé«˜ï¼Œcounter ç”¨äºç›¸åŒä¼˜å…ˆçº§æ—¶æŒ‰å…¥é˜Ÿé¡ºåº
    job_data = {
        "job_id": job_id,
        "api_url": api_url,
        "prompt": prompt,
        "seed": seed,
        "image_size": image_size,
        "width": width,
        "height": height,
        "steps": steps,
        "count": count,
        "ref_images": ref_images,
        "parallel": parallel,
    }
    await task_queue.put((1, current_counter, job_data))  # é»˜è®¤ä¼˜å…ˆçº§ 1
    
    mode = "å›¾ç”Ÿå›¾" if ref_images else "æ–‡ç”Ÿå›¾"
    mode_label = "å¹¶å‘" if parallel else "é¡ºåº"
    print(f"[{now_bjt()}] ğŸ“¥ ä»»åŠ¡å…¥é˜Ÿ: {job_id} ({mode}, {count}å¼ , {mode_label}), é˜Ÿåˆ—ä½ç½®: {queue_position}")

    return JSONResponse({
        "success": True,
        "job_id": job_id,
        "queue_position": queue_position,
        "message": f"ä»»åŠ¡å·²åŠ å…¥é˜Ÿåˆ—ï¼Œä½ç½® #{queue_position}"
    })


@app.get("/api/job/{job_id}")
async def api_job_status(job_id: str):
    """è·å–å•ä¸ªä»»åŠ¡çŠ¶æ€"""
    if job_id not in active_jobs:
        return JSONResponse({"success": False, "error": "ä»»åŠ¡ä¸å­˜åœ¨"}, status_code=404)
    
    job = active_jobs[job_id]
    return JSONResponse({
        "success": True,
        "data": {
            "job_id": job_id,
            "status": job.get("status"),
            "prompt": job.get("prompt"),
            "count": job.get("count"),
            "completed": job.get("completed", 0),
            "parallel": job.get("parallel"),
            "queued_ts": job.get("queued_ts"),
            "started_ts": job.get("started_ts"),
            "batch_total": job.get("batch_total"),
            "results": job.get("results", []),
            "error": job.get("error"),
        }
    })


@app.post("/api/job/{job_id}/ack")
async def api_job_ack(job_id: str):
    """ç¡®è®¤ä»»åŠ¡å®Œæˆï¼Œä» active_jobs ç§»é™¤"""
    if job_id in active_jobs:
        active_jobs.pop(job_id, None)
    return JSONResponse({"success": True})


@app.delete("/api/job/{job_id}")
async def api_cancel_job(job_id: str):
    """å–æ¶ˆæ’é˜Ÿä¸­çš„ä»»åŠ¡ï¼ˆåªèƒ½å–æ¶ˆ pending çŠ¶æ€çš„ï¼‰"""
    if job_id not in active_jobs:
        return JSONResponse({"success": False, "error": "ä»»åŠ¡ä¸å­˜åœ¨"}, status_code=404)
    
    job = active_jobs[job_id]
    if job.get("status") != "pending":
        return JSONResponse({"success": False, "error": "åªèƒ½å–æ¶ˆæ’é˜Ÿä¸­çš„ä»»åŠ¡"}, status_code=400)
    
    # ä»é˜Ÿåˆ—ä¸­ç§»é™¤è¯¥ä»»åŠ¡
    temp_queue = []
    found = False
    
    while not task_queue.empty():
        try:
            priority, counter, job_data = task_queue.get_nowait()
            if job_data["job_id"] != job_id:
                temp_queue.append((priority, counter, job_data))
            else:
                found = True
        except asyncio.QueueEmpty:
            break
    
    # é‡æ–°æ”¾å›é˜Ÿåˆ—
    for item in temp_queue:
        await task_queue.put(item)
    
    # æ ‡è®°ä¸ºå·²å–æ¶ˆ
    active_jobs[job_id]["status"] = "cancelled"
    active_jobs.pop(job_id, None)
    print(f"[{now_bjt()}] âŒ ä»»åŠ¡å·²å–æ¶ˆ: {job_id}")
    return JSONResponse({"success": True})


@app.post("/api/job/{job_id}/cancel")
async def api_cancel_generating(job_id: str):
    """å–æ¶ˆæ­£åœ¨ç”Ÿæˆçš„ä»»åŠ¡ï¼ˆæ ‡è®°ä¸ºå–æ¶ˆï¼Œè®© worker è·³è¿‡ï¼‰"""
    if job_id not in active_jobs:
        return JSONResponse({"success": False, "error": "ä»»åŠ¡ä¸å­˜åœ¨"}, status_code=404)
    
    # æ ‡è®°ä¸ºå·²å–æ¶ˆï¼Œworker æ£€æµ‹åˆ°åä¼šè·³è¿‡
    # æ³¨æ„ï¼šä¸ç«‹å³åˆ é™¤ï¼Œè®© execute_generation æ£€æµ‹åˆ°å–æ¶ˆåè‡ªè¡Œé€€å‡º
    active_jobs[job_id]["status"] = "cancelled"
    print(f"[{now_bjt()}] âŒ ç”Ÿæˆä»»åŠ¡å·²å–æ¶ˆ: {job_id}")
    return JSONResponse({"success": True})


@app.post("/api/job/{job_id}/priority")
async def api_priority_job(job_id: str):
    """ç½®é¡¶æ’é˜Ÿä¸­çš„ä»»åŠ¡ï¼ˆç§»åˆ°é˜Ÿåˆ—æœ€å‰é¢ï¼‰"""
    if job_id not in active_jobs:
        return JSONResponse({"success": False, "error": "ä»»åŠ¡ä¸å­˜åœ¨"}, status_code=404)
    
    job = active_jobs[job_id]
    if job.get("status") != "pending":
        return JSONResponse({"success": False, "error": "åªèƒ½ç½®é¡¶æ’é˜Ÿä¸­çš„ä»»åŠ¡"}, status_code=400)
    
    # ä»é˜Ÿåˆ—ä¸­å–å‡ºæ‰€æœ‰ä»»åŠ¡ï¼Œæ‰¾åˆ°ç›®æ ‡ä»»åŠ¡å¹¶æå‡ä¼˜å…ˆçº§
    temp_queue = []
    found = False
    
    # å–å‡ºæ‰€æœ‰ä»»åŠ¡
    while not task_queue.empty():
        try:
            priority, counter, job_data = task_queue.get_nowait()
            if job_data["job_id"] == job_id:
                # æ‰¾åˆ°ç›®æ ‡ä»»åŠ¡ï¼Œè®¾ç½®ä¼˜å…ˆçº§ä¸º 0ï¼ˆæœ€é«˜ï¼‰
                temp_queue.append((0, counter, job_data))
                found = True
                print(f"[{now_bjt()}] â¬†ï¸ ä»»åŠ¡å·²ç½®é¡¶: {job_id}")
            else:
                temp_queue.append((priority, counter, job_data))
        except asyncio.QueueEmpty:
            break
    
    # é‡æ–°æ”¾å›é˜Ÿåˆ—
    for item in temp_queue:
        await task_queue.put(item)
    
    if found:
        # æ›´æ–°ä»»åŠ¡çŠ¶æ€
        active_jobs[job_id]["priority"] = 0
        active_jobs[job_id]["queued_ts"] = 0  # å‰ç«¯æ˜¾ç¤ºç”¨
        return JSONResponse({"success": True, "message": "ä»»åŠ¡å·²ç½®é¡¶"})
    else:
        return JSONResponse({"success": False, "error": "ä»»åŠ¡æœªåœ¨é˜Ÿåˆ—ä¸­æ‰¾åˆ°"}, status_code=404)


@app.post("/api/reorder")
async def api_reorder(request: Request):
    """é‡æ–°æ’åºå›¾ç‰‡ï¼Œæ¥æ”¶å®Œæ•´çš„ id é¡ºåºæ•°ç»„"""
    data = await request.json()
    order = data.get("order", [])  # [id1, id2, id3, ...]
    
    if not order:
        return JSONResponse({"success": False, "error": "ç¼ºå°‘ order å‚æ•°"}, status_code=400)
    
    async with aiosqlite.connect(DB_PATH) as db:
        # æ‰¹é‡æ›´æ–° sort_order
        for idx, image_id in enumerate(order):
            await db.execute(
                "UPDATE images SET sort_order = ? WHERE id = ?",
                (idx, image_id)
            )
        await db.commit()
    
    print(f"[{now_bjt()}] ğŸ”„ ç”»å»Šå·²é‡æ–°æ’åºï¼Œå…± {len(order)} å¼ å›¾ç‰‡")
    return JSONResponse({"success": True})


@app.post("/api/import")
async def api_import(file: UploadFile = File(...)):
    """å¯¼å…¥å¤–éƒ¨å›¾ç‰‡åˆ°ç”»å»Š"""
    from PIL import Image
    import io
    
    # è¯»å–æ–‡ä»¶å†…å®¹
    content = await file.read()
    
    # è·å–å›¾ç‰‡å°ºå¯¸
    try:
        img = Image.open(io.BytesIO(content))
        width, height = img.size
    except Exception:
        return JSONResponse({"success": False, "error": "æ— æ³•è¯»å–å›¾ç‰‡"}, status_code=400)
    
    # ä¿å­˜åˆ° output ç›®å½•
    ext = Path(file.filename).suffix.lower() or '.png'
    if ext not in ('.png', '.jpg', '.jpeg', '.webp'):
        ext = '.png'
    
    ts = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"{ts}_import_{uuid.uuid4().hex[:6]}{ext}"
    filepath = OUTPUT_DIR / filename
    
    with open(filepath, 'wb') as f:
        f.write(content)
    
    # è·å–ä¸‹ä¸€ä¸ª sort_order
    sort_order = await get_next_sort_order()
    
    # å†™å…¥æ•°æ®åº“
    async with aiosqlite.connect(DB_PATH) as db:
        await db.execute("""
            INSERT INTO images (job_id, filename, prompt, seed, image_size, width, height, steps, api_url, status, created_at, sort_order)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        """, (
            f"import_{uuid.uuid4().hex[:8]}",
            filename,
            "(å¯¼å…¥å›¾ç‰‡)",
            0,
            "custom",
            width,
            height,
            0,
            "",
            "imported",
            now_bjt(),
            sort_order
        ))
        last_id = (await db.execute("SELECT last_insert_rowid()")).fetchone()
        await db.commit()
        
        # è·å–æ’å…¥çš„è®°å½•
        cursor = await db.execute("SELECT * FROM images WHERE filename = ?", (filename,))
        db.row_factory = aiosqlite.Row
        cursor = await db.execute("SELECT * FROM images WHERE filename = ?", (filename,))
        row = await cursor.fetchone()
        record = dict(row) if row else None
    
    print(f"[{now_bjt()}] ğŸ“¥ å›¾ç‰‡å·²å¯¼å…¥: {filename} ({width}x{height})")
    
    return JSONResponse({
        "success": True,
        "data": record
    })


@app.delete("/api/images/{image_id}")
async def api_delete_image(image_id: int):
    await delete_image_record(image_id)
    return JSONResponse({"success": True})


@app.delete("/api/images")
async def api_clear_all():
    await clear_all_records()
    return JSONResponse({"success": True})


# ============ main ============

def main():
    print(f"\n{'='*60}")
    print(f"ğŸ¨ HunyuanImage API æµ‹è¯•å·¥å…·")
    print(f"âœ… http://localhost:{PORT}")
    print(f"{'='*60}\n")
    uvicorn.run(app, host="0.0.0.0", port=PORT, access_log=False)

if __name__ == "__main__":
    main()
